# Testing Strategy

This document outlines the testing strategy for the Instructions Composer project. Our goal is to ensure the reliability, maintainability, and quality of the codebase through a comprehensive and automated testing approach.

## Guiding Principles

- **Testing Pyramid:** We adhere to the testing pyramid model, prioritizing unit tests, followed by integration tests, and finally end-to-end (E2E) tests.
- **Fast & Reliable:** Tests must be fast and deterministic to provide quick feedback during development and in CI/CD pipelines.
- **Clarity:** Tests should be easy to read and understand. They serve as living documentation for the system's behavior.
- **Automation:** All tests should be automated and run as part of our Continuous Integration (CI) process.

## Tooling

- **Test Runner & Framework:** [Vitest](https://vitest.dev/) is our primary tool for running tests, providing a modern and fast testing experience.
- **Language:** All tests are written in [TypeScript](https://www.typescriptlang.org/) to leverage static typing and align with the project's source code.
- **Assertions:** We use the built-in `expect` assertion library provided by Vitest, which is Chai-compatible.
- **Mocks and Spies:** We use Vitest's built-in `vi` object (`vi.mock`, `vi.spyOn`, `vi.fn`) for creating mocks, stubs, and spies.
- **Code Coverage:** Code coverage is collected using Vitest's native support, which utilizes the `v8` coverage provider.

## Testing Levels

### 1. Unit Tests

- **Goal:** To verify the functionality of individual components (e.g., a function, class, or module) in isolation. These form the base of our testing pyramid.
- **Location:** Unit test files should be co-located with the source code they are testing, using the `*.test.ts` or `*.spec.ts` naming convention. For example, `src/core/parser.ts` will have its tests in `src/core/parser.test.ts`.
- **What to Test:**
  - Public API of modules.
  - Business logic and algorithms.
  - Boundary conditions and edge cases.
  - Error handling and expected failures.
- **Strategy:**
  - All external dependencies and collaborators (like file system access or network calls) must be mocked to ensure the test is isolated.

### 2. Integration Tests

- **Goal:** To verify that different modules or components work together as expected. They test the "glue" between units.
- **Location:** Integration tests will be placed in a dedicated `tests/integration` directory.
- **What to Test:**
  - Interactions between major components (e.g., the `build` command interacting with the `parser` and `resolver`).
  - API contracts between services.
  - Interactions with a test database or a mocked file system.
- **Strategy:**
  - Minimize mocking. Only mock external services or components that are out of scope for the integration test (e.g., third-party APIs).
  - Focus on the flow of data and control between modules.

### 3. End-to-End (E2E) Tests

- **Goal:** To test the entire application from the user's perspective, simulating real-world scenarios. For our CLI, this means invoking the command and verifying its behavior.
- **Location:** E2E tests will be placed in a dedicated `tests/e2e` directory.
- **What to Test:**
  - Core user workflows (e.g., `instructions-builder build --persona <persona> --output <file>`).
  - Handling of command-line arguments, options, and flags.
  - Correctness of stdout, stderr, and exit codes.
  - File system side-effects (e.g., creating output files).
- **Strategy:**
  - E2E tests will use Node.js's `child_process` module to execute the compiled CLI tool.
  - Assertions will be made against the process output, exit code, and any generated artifacts.
  - These tests should run against the compiled JavaScript output in the `dist` directory.

## Code Coverage

- **Goal:** We aim for a minimum of **80%** code coverage for our unit and integration tests.
- **Measurement:** Coverage reports are generated by running `vitest run --coverage`.
- **Philosophy:** While a high percentage is desirable, the primary goal is to ensure that all critical paths, complex logic, and essential features are thoroughly tested. 100% coverage is not a strict requirement.
- **Quality over quantity:** High coverage doesn’t guarantee good tests—focus on meaningful tests that cover critical paths and edge cases.
- **Critical code:** Aim for near 100% coverage on security, business logic, and error handling.
- **Trivial code:** Avoid excessive testing of trivial code paths that do not add significant value.

## Running Tests

### Local Development

Run all tests:

```bash
npm test
```

Run tests in watch mode:

```bash
npm run test:watch
```

Generate a coverage report:

```bash
npm run coverage
```

### Continuous Integration (CI)

All tests are automatically executed on every push and pull request to the `main` branch, as configured in `.github/workflows/ci.yml`. The CI pipeline will fail if any tests fail, preventing regressions from being merged.

## Best Practices

- **Arrange, Act, Assert (AAA):** Structure your tests using the AAA pattern for clarity.

  ```typescript
  it('should do something', () => {
    // Arrange: Set up the test, initialize objects, create mocks.
    const { a, b } = setup();

    // Act: Execute the code being tested.
    const result = sum(a, b);

    // Assert: Check the outcome.
    expect(result).toBe(a + b);
  });
  ```

- **Descriptive Naming:** Test suites (`describe`) and test cases (`it`) should have clear, descriptive names that explain their purpose.
- **Keep Tests Simple:** Avoid logic (loops, conditionals) in your test cases. Each test should have a single, clear purpose.
- **Focus on Behavior:** Test the public-facing behavior of a component, not its internal implementation details. This makes tests more resilient to refactoring.
- **Use Fixtures:** For complex data setups, use fixtures to create reusable test data. This keeps tests clean and focused on behavior.
